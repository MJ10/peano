task: train

train_interval: [500, 1000000]
eval_interval: [0, 200]

trainer:
    train_domains:
        - subst-eval
        - subst-eval
        - mix(subst-eval, comb-like)
        - mix(subst-eval, comb-like)
        - mix(subst-eval, comb-like, one-step-add-eq)
        - mix(subst-eval, comb-like, one-step-add-eq)

    eval_domains:
        - subst-eval
        - comb-like
        - one-step-add-eq

    iterations: 10
    batch_size: 500
    n_searchers: 5
    max_depth: 10
    max_nodes: 200
    rerank_top_k: 200
    algorithm: 'policy-beam-search'

    model:
        type: contrastive-policy
        discard_unsolved: true

        gru:
            embedding_size: 64
            hidden_size: 256
            layers: 2

        epochs: 20
        batch_size: 8
        lr: 0.0000001

        interaction: dot-product
        normalize: true

job:
    wandb_project: peano

hydra:
    job:
        chdir: true
